model: 'clip'

train_file:  ['data/flickr30k_train.json']
val_file: 'data/flickr30k_val.json'                
test_file: 'data/flickr30k_test.json'
image_root: '/remote-home/songtianwei/research/albef/ALBEF/datasets/' #flickr30k-images/
output_dir: '/remote-home/songtianwei/research/albef/ALBEF/output/clip_natural/'
bert_config: 'configs/config_bert.json'

image_res: 224
batch_size_train: 24  # ori : 32
batch_size_test: 64

alpha: 0.4
distill: True
warm_up: True

optimizer: {opt: adamW, lr: 1e-5, weight_decay: 0.02} 
schedular: {sched: cosine, lr: 1e-5, epochs: 10, min_lr: 1e-6, decay_rate: 1, warmup_lr: 1e-5, warmup_epochs: 1, cooldown_epochs: 0}







