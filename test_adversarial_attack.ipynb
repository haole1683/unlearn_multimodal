{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b34dbe3-09c8-4a3f-8f4a-dffc25239e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import ruamel.yaml as yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "\n",
    "# Dataset\n",
    "from dataset import create_dataset, create_sampler, create_loader, normalize_fn\n",
    "from models.model_gan_generator import NetG\n",
    "import utils\n",
    "import clip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aad2b85-869c-4d27-a94e-f9d9c1d6e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/remote-home/songtianwei/research/unlearn_multimodal/output/train_generator_max_loss/checkpoint_epoch_10.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98442878-dd48-41ee-9e16-dca8ff40adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = NetG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18a64f8-ba20-4178-b477-2c5cc8a78e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path)\n",
    "generator.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011306e8-e4b4-4918-b9ea-5d529828ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Top predictions:\n",
      "\n",
      "           snake: 65.19%\n",
      "          turtle: 12.45%\n",
      "    sweet_pepper: 3.92%\n",
      "          lizard: 1.88%\n",
      "       crocodile: 1.71%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "# Prepare the inputs\n",
    "image, class_id = cifar100[3637]\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
